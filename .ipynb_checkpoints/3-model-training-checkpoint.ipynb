{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718f54c3-6d20-4ed0-9752-e1751e6b84e5",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/nicholasmetherall/digital-earth-pacific-macblue-activities/blob/main/attachments/images/DE_Pacific_banner.JPG?raw=true\" width=\"900\"/>\n",
    "\n",
    "Figure 1.1.a. Jupyter environment + Python notebooks\n",
    "\n",
    "# Digital Earth Pacific Notebook 1 prepare postcard and load data to csv\n",
    "\n",
    "The objective of this notebook is to prepare a geomad postcard for your AOI (masking, scaling and loading additional band ratios and spectral indices) and sampling all the datasets into a csv based on your training data geodataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887498ee",
   "metadata": {},
   "source": [
    "## Step 1.1: Configure the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98bda661-ae78-4f82-82b3-e68a5aa32d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba2c3e96-d81a-4a01-b638-20cde81d98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nm-tongatapu-11122025\n"
     ]
    }
   ],
   "source": [
    "# Predefined variable for title and version\n",
    "\n",
    "# Enter your initials\n",
    "initials = \"nm\"\n",
    "\n",
    "# site\n",
    "site = \"tongatapu\"\n",
    "\n",
    "# Date\n",
    "date = datetime.now()\n",
    "\n",
    "# Make a clean version string\n",
    "version = f\"{initials}-{site}-{date.strftime('%d%m%Y')}\"\n",
    "print(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd17e13-a9d8-4c1a-9f4f-37caea2ca87e",
   "metadata": {},
   "source": [
    "### Postcard csv\n",
    "\n",
    "The objective of this notebook was to train the machine learning model that will allow us to classify an area with land cover classes defined through the training data.\n",
    "\n",
    "Step 1.2. Input the training data to sample geomad data from the postcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f992dfb-7553-4914-afe9-23ae4978d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_df = gpd.read_file(f\"training-data/{version}-training.csv\")\n",
    "joined_df = joined_df.astype(\"float32\")\n",
    "# joined_df\n",
    "joined_df = gpd.read_file(\"training-data/nm-tongatapu-11122025_postcard_4-training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6328106-27ca-47e1-9213-bff93576b276",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['y', 'x'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m joined_df=\u001b[43mjoined_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/conda/envs/notebook/lib/python3.11/site-packages/pandas/core/frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/conda/envs/notebook/lib/python3.11/site-packages/pandas/core/generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/conda/envs/notebook/lib/python3.11/site-packages/pandas/core/generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/srv/conda/envs/notebook/lib/python3.11/site-packages/pandas/core/indexes/base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['y', 'x'] not found in axis\""
     ]
    }
   ],
   "source": [
    "joined_df=joined_df.drop(columns=[\"y\", \"x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8f0d848-343a-4f73-9d71-874e0ea0e422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['LULC_code', 'nir', 'red', 'blue', 'green', 'emad', 'smad', 'bcmad',\n",
       "       'nir08', 'nir09', 'swir16', 'swir22', 'coastal', 'rededge1', 'rededge2',\n",
       "       'rededge3', 'mndwi', 'ndti', 'cai', 'ndvi', 'evi', 'savi', 'ndwi',\n",
       "       'b_g', 'b_r', 'swir22_swir16', 'mci', 'ndci', 'nbi', 'ndmi', 'bsi',\n",
       "       'awei', 'tc_wetness'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(joined_df.columns))\n",
    "joined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4c67ffc-f848-437b-8955-3e5fc8c70f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, test_data = train_test_split(joined_df, test_size=0.2, random_state=1337)\n",
    "\n",
    "# The classes are the first column\n",
    "classes = np.array(training_data)[:, 0]\n",
    "\n",
    "# The observation data is everything after the second column\n",
    "observations = np.array(training_data)[:, 1:]\n",
    "\n",
    "# Create a model...\n",
    "classifier = RandomForestClassifier(max_depth=4)\n",
    "\n",
    "# ...and fit it to the data\n",
    "model = classifier.fit(observations, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5af7821d-59ea-449a-b74c-53c942dca7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/nm-tongatapu-11122025-test.model']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dynamically create the filename with f-string\n",
    "file_path = f\"models/{version}-test.model\"\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9aaca9eb-1d95-4cf2-ab1f-ac7d50eb9b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>38</td>\n",
       "      <td>71</td>\n",
       "      <td>12</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   1   2   3   4  5  6  All\n",
       "row_0                           \n",
       "1      31   7   1   0  0  0   39\n",
       "2       5  54   0   3  2  0   64\n",
       "3       1   2  11   0  0  0   14\n",
       "4       1   4   0  30  1  0   36\n",
       "5       0   4   0   9  5  0   18\n",
       "6       0   0   0   0  0  6    6\n",
       "All    38  71  12  42  8  6  177"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_actual = np.array(test_data)[:, 0]\n",
    "\n",
    "test_predicted = model.predict(np.array(test_data)[:,1:])\n",
    "\n",
    "\n",
    "unique_labels = sorted(np.unique(np.concatenate([np.asarray(test_actual), np.asarray(test_predicted)])))\n",
    "\n",
    "\n",
    "pd.crosstab(test_actual, test_predicted, margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fbdd6d4-94db-40da-b0cc-bd1b35551370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7740112994350282"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(test_actual, test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa188f3f-a751-42f0-a366-bb35ef4c165e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa: 0.6980\n",
      "Quadratic weighted kappa: 0.8221\n",
      "Bootstrap mean kappa: 0.6970, 95% CI [0.6131, 0.7785]\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.79      0.81        39\n",
      "           2       0.76      0.84      0.80        64\n",
      "           3       0.92      0.79      0.85        14\n",
      "           4       0.71      0.83      0.77        36\n",
      "           5       0.62      0.28      0.38        18\n",
      "           6       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.77       177\n",
      "   macro avg       0.81      0.76      0.77       177\n",
      "weighted avg       0.77      0.77      0.76       177\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred) with labels: ['1' '2' '3' '4' '5' '6']\n",
      "[[31  7  1  0  0  0]\n",
      " [ 5 54  0  3  2  0]\n",
      " [ 1  2 11  0  0  0]\n",
      " [ 1  4  0 30  1  0]\n",
      " [ 0  4  0  9  5  0]\n",
      " [ 0  0  0  0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "# -- Cohen's kappa (and extras) for the test set --\n",
    "from sklearn.metrics import cohen_kappa_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Ensure these variables exist and are aligned\n",
    "# test_actual = np.array(test_data)[:, 0]      # <- you already had this\n",
    "# test_predicted = model.predict(np.array(test_data)[:,1:])  # <- you already had this\n",
    "\n",
    "assert len(test_actual) == len(test_predicted), \"y_true and y_pred must have same length\"\n",
    "\n",
    "# If you want to fix label ordering / include labels with zero counts, provide labels=...\n",
    "unique_labels = np.unique(np.concatenate([np.asarray(test_actual), np.asarray(test_predicted)]))\n",
    "\n",
    "# Cohen's kappa (unweighted)\n",
    "kappa = cohen_kappa_score(test_actual, test_predicted, labels=unique_labels)\n",
    "# Quadratic weighted kappa (useful when class order/ordinality matters)\n",
    "kappa_quad = cohen_kappa_score(test_actual, test_predicted, labels=unique_labels, weights=\"quadratic\")\n",
    "\n",
    "print(f\"Cohen's kappa: {kappa:.4f}\")\n",
    "print(f\"Quadratic weighted kappa: {kappa_quad:.4f}\")\n",
    "\n",
    "# Optional: bootstrap 95% CI for kappa (can be slow if n_boot large)\n",
    "def bootstrap_kappa(y_true, y_pred, n_boot=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    ks = []\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    n = len(y_true)\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        ks.append(cohen_kappa_score(y_true[idx], y_pred[idx], labels=unique_labels))\n",
    "    ks = np.array(ks)\n",
    "    return np.mean(ks), np.percentile(ks, 2.5), np.percentile(ks, 97.5)\n",
    "\n",
    "mean_k, ci_low, ci_high = bootstrap_kappa(test_actual, test_predicted, n_boot=1000, seed=42)\n",
    "print(f\"Bootstrap mean kappa: {mean_k:.4f}, 95% CI [{ci_low:.4f}, {ci_high:.4f}]\")\n",
    "\n",
    "# Print classification report and confusion matrix for context\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(test_actual, test_predicted, labels=unique_labels, zero_division=0))\n",
    "\n",
    "print(\"Confusion matrix (rows=true, cols=pred) with labels:\", unique_labels)\n",
    "print(confusion_matrix(test_actual, test_predicted, labels=unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e29720-9442-4750-afc8-52ad9535fed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
